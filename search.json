[{"title":"Resilient Distributed Datasets","date":"2020-05-28T05:15:55.000Z","url":"/2020/05/27/rdd/","categories":["paper"],"content":"I took CS 245 in this January which was taught by Matei Zaharia, the creator of Apache Spark. Recently, I need to use Spark for my project, so I revisited this paper: Resilient Distributed Datasets: A Fault-Tolerant Abstraction for In-Memory Cluster Computing . Here are some notes: Resilient Distributed Datasets (RDD): Read-only, partitioned collection of records. Can be only created through deterministic operations on either(1) data in stable storage or (2) other RDDs. [Transformation - map, filter, join] User can control: (1) persistence (2) partitioning. Life of a RDDs: Creation (through coarse-grained transformations) Perform actions (e.g. count, collect) Persist (in memory or disk) Advantages: RDDs do not need to incur the overhead of checkpointing, as they can be recovered using lineage. Only the lost partitions of an RDD need to be recomputed upon failure, and they can be recomputed in parallel on different nodes, without having to roll back the whole program. Its immutable nature lets a system mitigate slow nodes by running backup copies of slow tasks. In bulk operations, a runtime can schedule tasks based on data locality to improve performance. RDDs degrade gracefully when there is not enough memory to store them, can be stored on disk. Applications: batch operations that apply the same operation to all elements (not suitable for applications that make aync fine-grained updates) Usage: Write driver program that connects to a cluster of workers Driver: defines one or more RDDs, tracks the RDDs’ lineage. Worker: long-lived processes that can store RDD partitions in RAM across operations. Users provide arguments to RDD operations like map by passing closures (function literals) Scala represents each closure as a Java object The object can be serialized and loaded on another node to pass the closure across the network. Variables bound in the closure as fields in the object During execution: Driver finds variables attached to closure, wraps them into an object, then serializes the object. The object will then be passed to worker nodes. Worker deserializes and executes. Example applications: Logistic Regression PageRank Representing RDDs Common interface w/ 5 pieces of information: partitions() preferredLocations(p) dependencies() iterator(p, parentIters) partitioner() Dependencies: Narrow v.s. Wide: whether each parition of the parent RDD is used by at most one partition of the child RDD. Differences: Narrow dependencies allow for pipelined execution on one cluster node. Recovery after a node failure is more efficient with a narrow dependency. Implementation "},{"title":"Column-Oriented Database Systems","date":"2020-02-10T17:03:42.000Z","url":"/2020/02/10/compression-column-oriented-database/","categories":["paper"],"content":"Introduction Column-oriented database system: each attribute is stored in a separate column, such that successive values of that attribute are stored consecutively on disk. Compression techniques: Dictionary schemas Compress values from more than one row at a time (e.g. run-length encoding) Architecture: Relational interface on top of a column-store. Each table is physically represented as a collection of projections. Compression schemes Null suppression Dictionary encoding Cache-conscious optimization Parsing into single values Run-length encoding (RLE) Bit-vector encoding Heavyweight compression schemes Lempel-ziv encoding Compressed query execution Query Executor Architecture Compression block Datasource operator "},{"title":"A History and Evaluation of System R","date":"2020-02-10T00:15:44.000Z","url":"/2020/02/09/system-r/","categories":["paper"],"content":"Link: A History and Evaluation of System R Summary Demonstrate the advantages of relational data model Describe 3 principle phases of the System R Introduction Trends: data independence - immunity of applications to change in storage structure and access strategy Relational data model: Proposed by E.F. Codd, store information in two ways: by the contents of records stored in the database by the ways in which these records are connected together Two properties: all information is represented by data values the system supports a very high-level language Phase 0 Relational access method: XRM. XRM stores relations in the form of “tuples”, each of which has a unique 32-bit “tuple identifier”: TID. The most challenging task: design of optimizer algorithms for efficient execution of SQL statements on top of XRM. =&gt; optimizer made extensive use of inversions Demonstrated the usability of SQL. Pros &amp; Cons: Pros: fast w/ finding distinct jobs Cons: Too many I/Os For each tuple, look up all its fields Use “inversions” to find TIDs with a given value for a field Lessons learned: The optimizer should take into account not just the cost of fetching tuples, but the costs of creating and manipulating TID lists. A better measure of cost would have been number of “I/Os”. Cost measure should be a weighted sum of CPU time and I/O count. Importance of “join” Simpler interaction, minimize the “path length” for simple SQL statements. Phase 1: B-Tree Assess method: Research Storage System (RSS) Store data in the individual records of the database. Pros: all the data value of a record could be fetched by a single I/O. B-tree indexes. Optimizing SQL processor: Relational Data System (RDS) Subsystems: View &amp; Authorization subsystem View definition in the form of an SQL parse tree. Authorization is based on privileges, controlled by GRANT and REVOKE. Recovery subsystem Media(disk) failure: image dump + change log. System failure: change log + shadow pages. Why do we need both shadow pages and change logs? You may need log for transaction replay You can only have log because shadow mechanism is quite expensive for large logs Transaction failure: process the change log backwards. Locking subsystem “predicate locks” (abandoned) determine whether predicates are satisfiable are difficult and time-consuming two predicates may appear to conflict hierarchy of locks (used by MySQL) “intention” locks References"},{"title":"Last month of 2018","date":"2018-12-08T07:24:17.000Z","url":"/2018/12/07/last-month-of-2018/","categories":["life"],"content":"“Is life always this hard, or is it just when you’re a kid?”“Always like this.” Now is a good time for reflection and planning, as it’s December already. I’ll try to summarize my 2018 in a few sentences and plan for 2019. 2018 My favorite book of the year is When Breath Becomes Air, which always reminds me of the saying: being towards death. If possible, I would like to spend the rest of my life striving for a better world and helping others in need. I moved to a new house, got married to my soulmate, transferred to a new team and buying my first investment property. I’m not afraid of growing old, as long as my wisdom isn’t left behind. I learned C++, blockchain technologies and built a mini-program for my wedding, started Udacity ML Nanodegree but haven’t finished, applied for a Stanford graduate certificate but haven’t started. Tried skiing once, played “several” SC2 games, had some short but memorable trips. 2019 [P0] Healthy body as a foundation of everything. Exercise every day without excuse. Eat healthier with raw ingredients. Sleep well. [P0] Family as a team. Effective communication. Be selfless, patient and kind. [P1] Efficient work. Automate repeated work. Plan ahead to reduce regression. Enhance coding/design/presentation skills. [P1] Personal development. Stanford graduate certificate 3/4. Read engineering blogs and infra related books. Investigate use cases for retail, finance and healthcare fields. [P2] Live a meaningful life. Volunteering. Travel to Israel (…or anywhere else). Cook more delicious food (or play Overcooked better XD) Photography: “I just wanna buy a Leica”. “When you feel like quitting, remember why you started.”"},{"title":"Reservoir Sampling","date":"2018-04-29T19:48:11.000Z","url":"/2018/04/29/reservoir-%20sampling/","tags":["sample"],"categories":["algorithm"],"content":"Reservoir sampling is a family of randomized algorithms for randomly choosing a sample of k items from a list S containing n items, where n is either a very large or unknown number. Typically n is large enough that the list doesn’t fit into main memory. ProblemChoose k entries from n numbers. Make sure each number is selected with the probability of k/n Idea Choose k items and put them into the reservoir. For (k+1)th item, pick it with probability k/(k+1), and randomly replace a number in the reservoir. For (k+i)th item, pick it with probability k/(k+i), and randomly replace a number in the reservoir. Repeat until k+i reaches n. ExampleSample size 1 Choose 1 from [1, 2, 3, 4] =&gt; initial reservoir: [1] For 2: with probability 1/2, keep it (discard the old one aka 1) with probability 1 - 1/2 = 1/2, keep the old item (ignore the new one) For 1, the probability that it keeps staying in the reservoir is: P(1 was in the reservoir last time) * P(1 is not replaced by 2) = 1 * (1 - 1/2 * 1) = 1/2 For 3: For 1, the probability that it keeps staying in the reservoir is: P(1 was in the reservoir last time) * P(1 is not replaced by 3) P(1 was in the reservoir last time) * (1 - P(3 is selected and replaces 1)) = 1/2 * (1 - 1/3 * 1) = 1/2 * 2/3 = 1/3 Same for 4 Applications Linked List Random Node Random Pick Index More info: Wiki Leetcode "},{"title":"Binary Indexed Tree","date":"2018-04-28T20:20:53.000Z","url":"/2018/04/28/binary-indexed-tree/","tags":["algorithm"],"categories":["data structure"],"content":"A Fenwick tree or binary indexed tree is a data structure that can efficiently update elements and calculate prefix sums in a table of numbers. This structure was proposed by Peter Fenwick in 1994 to improve the efficiency of arithmetic coding compression algorithms. Problem add marble to box i sum marbles from box k to box l Naive SolutionIdeaExampleApplications Range Sum Query - Mutable More info: Topcoder "},{"title":"Java Concurrency","date":"2018-04-04T13:54:12.000Z","url":"/2018/04/04/java-concurrency/","tags":["concurrency"],"categories":["system"],"content":"Threads and Runnables Before starting a new thread you have to specify the code to be executed by this thread, often called the task. This is done by implementing Runnable - a functional interface defining a single void no-args method run(). Due to concurrent execution we cannot predict if the runnable will be invoked before or after printing ‘done’. The order is non-deterministic, thus making concurrent programming a complex task in larger applications. Executors ExecutorService as a higher level replacement for working with threads directly. Executors are capable of running asynchronous tasks and typically manage a pool of threads, so we don’t have to create new threads manually. Callables and FuturesIn addition to Runnable executors support another kind of task named Callable. Callables are functional interfaces just like runnables but instead of being void they return a value. SynchronizedWhen writing such multi-threaded code you have to pay particular attention when accessing shared mutable variables concurrently from multiple threads. Let’s just say we want to increment an integer which is accessible simultaneously from multiple threads. We define a field count with a method incrementSync() to increase count by one: When using incrementSync() concurrently we get the desired result count of 10000. No race conditions occur any longer and the result is stable with every execution of the code:Internally Java uses a so called monitor also known as monitor lock or intrinsic lock in order to manage synchronization. This monitor is bound to an object, e.g. when using synchronized methods each method share the same monitor of the corresponding object. All implicit monitors implement the reentrant characteristics. Reentrant means that locks are bound to the current thread. A thread can safely acquire the same lock multiple times without running into deadlocks (e.g. a synchronized method calls another synchronized method on the same object). AtomicIntegerAn operation is atomic when you can safely perform the operation in parallel on multiple threads without using the synchronized keyword or locks. Internally, the atomic classes make heavy use of compare-and-swap (CAS), an atomic instruction directly supported by most modern CPUs. Those instructions usually are much faster than synchronizing via locks. So my advice is to prefer atomic classes over locks in case you just have to change a single mutable variable concurrently. By using AtomicInteger as a replacement for Integer we’re able to increment the number concurrently in a thread-safe manor without synchronizing the access to the variable. The method incrementAndGet() is an atomic operation so we can safely call this method from multiple threads. AtomicInteger supports various kinds of atomic operations. The method updateAndGet() accepts a lambda expression in order to perform arbitrary arithmetic operations upon the integer: ConcurrentMapThe interface ConcurrentMap extends the map interface and defines one of the most useful concurrent collection types. Java 8 introduces functional programming by adding new methods to this interface. Reference"},{"title":"Using a Stack to Evaluate an Expression","date":"2018-04-04T02:10:43.000Z","url":"/2018/04/03/stack-evaluate-expression/","tags":["leetcode","stack"],"categories":["data structure"],"content":"Evaluate a postfix expressionPostfix expression: Operand1 Operand2 op Evaluate a infix expressionInfix expression: Operand1 op Operand2 Reference   "},{"title":"Predict the Winner","date":"2018-03-29T03:08:45.000Z","url":"/2018/03/28/predict-the-winner/","tags":["leetcode","dynamic programming"],"categories":["algorithm"],"content":"ProblemGiven an array of scores that are non-negative integers. Player 1 picks one of the numbers from either end of the array followed by the player 2 and then player 1 and so on. Each time a player picks a number, that number will not be available for the next player. This continues until all the scores have been chosen. The player with the maximum score wins. Given an array of scores, predict whether player 1 is the winner. You can assume each player plays to maximize his score. Recursion Idea i == j -&gt; pick i i != j pick i -&gt; let player2 pick in (i + 1 … j) pick j -&gt; let player2 pick in (i … j - 1) compare the values between these 2 options, find the max. Solution AnalysisTime complexity: O(2^n)Space complexity: O(n) Memorization IdeaIn the last approach, a lot of duplicate calls to predictHelper function will be made with the same set of arguments, since the same subarray could be obtained by following different paths in the search space. This redundancy can be removed by making use of memoization. Solution AnalysisTime complexity: O(n^2)Space complexity: O(n^2) DP Idea dp[i][j]: maximum effective score possible for the subarray nums[i,j]. dp[i][j] = Math.max((nums[i] - dp[i + 1][j]), nums[j] - dp[i][j - 1]) Solution AnalysisTime complexity: O(n^2)Space complexity: O(n^2) / O(n) More info Leetcode Topcoder MIT Dynamic Programming: Advanced DP "},{"title":"Knuth–Morris–Pratt Algorithm","date":"2018-03-29T03:05:50.000Z","url":"/2018/03/28/kmp/","tags":["string"],"categories":["algorithm"],"content":"TL;DRIn a word, KMP records the suffix substring which is a prefix of the string with max length at position i. Preprocessing KMP algorithm does preproceses pattern[] and constructs an auxiliary lps[] of size m (same as size of pattern) which is used to skip characters while matching. name lps indicates longest proper prefix which is also suffix. A proper prefix is prefix with whole string not allowed. For example, prefixes of “ABC” are “”, “A”, “AB” and “ABC”. Proper prefixes are “”, “A” and “AB”. Suffixes of the string are “”, “C”, “BC” and “ABC”. lps[i] = the longest proper prefix of pat[0..i] which is also a suffix of pat[0..i]. For the pattern “ababaca”, lps=[0, 0, 1, 2, 3, 0, 1]. Search More info Leetcode Geeks For Geeks Knuth-Morris-Pratt String Matching 字符串匹配的KMP算法 "},{"title":"Hello 2018","date":"2018-01-05T06:04:44.000Z","url":"/2018/01/04/2018-plan/","categories":["life"],"content":"“May your choices reflect your hopes, not your fears.”"},{"title":"Binary Search","date":"2017-09-09T22:36:46.000Z","url":"/2017/09/09/binary-search/","tags":["array","leetcode"],"categories":["algorithm"],"content":"ProblemGiven an array of citations (each citation is a non-negative integer) of a researcher, write a function to compute the researcher’s h-index (citations array is sorted in ascending order). According to the definition of h-index on Wikipedia: “A scientist has index h if h of his/her N papers have at least h citations each, and the other N − h papers have no more than h citations each.” For example, given citations = [3, 0, 6, 1, 5], which means the researcher has 5 papers in total and each of them had received 3, 0, 6, 1, 5 citations respectively. Since the researcher has 3 papers with at least 3 citations each and the remaining two with no more than 3 citations each, his h-index is 3. Note: If there are several possible values for h, the maximum one is taken as the h-index. Solution NotesArrays.binarySearch() returns a negative value that is equivalent to -[insertion point] - 1, where insertion point is defined as the index at which the search key would be inserted into the array or list."}]